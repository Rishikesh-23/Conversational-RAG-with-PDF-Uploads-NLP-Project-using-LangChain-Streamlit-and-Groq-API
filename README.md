# Conversational-RAG-with-PDF-Uploads-using-LangChain-Streamlit-and-Groq-API

## Table of Contents
1. [Project Title](#project-title)
2. [Project Description](#project-description)
3. [Key Features](#key-features)
4. [Tech Stack](#tech-stack)
5. [Setup Instructions](#setup-instructions)
    - [Prerequisites](#prerequisites)
    - [Installation Steps](#installation-steps)
6. [Usage](#usage)
7. [File Structure](#file-structure)
8. [Example Workflow](#example-workflow)
9. [Future Enhancements](#future-enhancements)
10. [License](#license)
11. [Contributors](#contributors)
12. [Acknowledgments](#acknowledgments)

---

## Project Title
**Conversational Retrieval-Augmented Generation (RAG) with PDF Uploads and Chat History**

---

## Project Description
This project provides a user-friendly interface for interacting with the content of uploaded PDF files using Conversational Retrieval-Augmented Generation (RAG). Built with **Streamlit**, the application enables users to ask questions about uploaded PDFs and maintains a dynamic, contextual chat history for efficient and seamless information retrieval. It leverages **Groq's Gemma2-9b-It** model for language understanding and **Chroma Vectorstore** for document embeddings and retrieval.

---

## Key Features
1. **PDF Upload Support:**
   - Users can upload one or multiple PDF files.
   - The application processes PDFs and splits their content for efficient embedding and retrieval.

2. **Conversational RAG:**
   - Combines chat history with document-based context to answer user questions effectively.
   - Reformulates ambiguous questions using history-aware retrievers.

3. **Stateful Chat History:**
   - Maintains user interactions across sessions.
   - Stores and displays the chat history for improved user experience.

4. **Advanced Embedding and Retrieval:**
   - Uses `HuggingFace` embeddings (`all-MiniLM-L6-v2`) for document vectorization.
   - Efficient vector-based document retrieval via `Chroma`.

5. **Dynamic LLM Integration:**
   - Powered by **Groq Gemma2-9b-It** for high-performance question answering.

6. **Streamlit Interface:**
   - Clean and intuitive UI for uploading files, entering API keys, and asking questions.

---

## Tech Stack
- **Frontend**: Streamlit
- **Backend**: Python
- **Machine Learning Models**:
  - HuggingFace (`all-MiniLM-L6-v2`)
  - Groq's Gemma2-9b-It
- **Document Processing**: PyPDFLoader
- **Vectorstore**: Chroma

---

## Setup Instructions

### Prerequisites
1. Install Python 3.8 or later.
2. Ensure you have the following Python libraries installed:
   - `streamlit`
   - `langchain`
   - `faulthandler`
   - `dotenv`
   - `PyPDFLoader`
   - `Chroma`
   - `HuggingFace`

3. Obtain a **Groq API Key** from the Groq platform.

### Installation Steps
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/conversational-rag.git
   cd conversational-rag
   ```

2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Set up your environment variables:
   - Create a `.env` file in the project directory and add your HuggingFace token:
     ```
     HF_TOKEN=your_huggingface_token
     ```

4. Run the Streamlit application:
   ```bash
   streamlit run app.py
   ```

---

## Usage
1. **Start the Application**:
   - Enter your **Groq API Key** when prompted.

2. **Upload PDF Files**:
   - Select and upload one or more PDF files.

3. **Ask Questions**:
   - Type your question into the input box.
   - View responses generated by the Conversational RAG system.

4. **Chat History**:
   - Access and review the chat history for context-based conversation continuity.

---

## File Structure
```
├── app.py                # Main application script
├── requirements.txt      # Required Python libraries
├── .env                  # Environment variables (e.g., API keys)
├── README.md             # Project documentation
├── temp.pdf              # Temporary storage for uploaded PDFs
```

---

## Example Workflow
1. **Input**:
   - Upload a PDF titled `example.pdf`.
   - Ask: *"What is the summary of the first section?"*

2. **Process**:
   - Extract content from `example.pdf`.
   - Generate embeddings and retrieve relevant sections.

3. **Output**:
   - Receive a concise response: *"The first section discusses XYZ topics in detail."*

4. **Continue Conversation**:
   - Ask: *"What about the second section?"*
   - Get a contextualized answer based on the PDF.

---

## Future Enhancements
1. Add support for other document formats (e.g., DOCX, TXT).
2. Enhance the UI with advanced features (e.g., topic highlighting in answers).
3. Integrate multilingual support for documents and queries.


---

## Contributors
- **Rishikesh**  
- LinkedIn: www.linkedin.com/in/rishikesh-a12090285
- Email: rishikesh23@kgpian.iitkgp.ac.in

---

## **License**

This project is licensed under the MIT License. See the `LICENSE` file for details.

---
